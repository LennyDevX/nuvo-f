import ai, { DEFAULT_MODEL, defaultFunctionDeclaration } from '../config/ai-config.js';
import { incrementTokenCount } from '../middlewares/logger.js';
import env from '../config/environment.js';

/**
 * Utilidad para timeout y reintentos
 * @param {Function} fn - Función a ejecutar con timeout y reintentos
 * @param {Object} options - Opciones de timeout y reintentos
 * @param {Number} options.timeoutMs - Tiempo máximo de espera en milisegundos
 * @param {Number} options.maxRetries - Número máximo de reintentos
 * @param {Number} options.backoffMs - Tiempo de espera entre reintentos en milisegundos
 * @returns {Promise<any>} - Resultado de la función
 */
async function withTimeoutAndRetry(fn, { timeoutMs = 30000, maxRetries = 2, backoffMs = 2000 } = {}) {
  let attempt = 0;
  while (attempt <= maxRetries) {
    try {
      return await Promise.race([
        fn(),
        new Promise((_, reject) => setTimeout(() => reject(new Error('Timeout esperando respuesta de Gemini')), timeoutMs))
      ]);
    } catch (err) {
      if (attempt >= maxRetries) throw err;
      // Solo reintenta en timeout o errores de red
      if (err.message && (err.message.includes('Timeout') || err.message.includes('network'))) {
        await new Promise(r => setTimeout(r, backoffMs * Math.pow(2, attempt)));
        attempt++;
      } else {
        throw err;
      }
    }
  }
}

/**
 * Procesa una solicitud a la API de Gemini
 * @param {Object|String} contents - Contenido del prompt o historial de mensajes
 * @param {String} model - Modelo de Gemini a utilizar
 * @param {Object} params - Parámetros adicionales
 * @returns {Promise<Object>} - Respuesta de Gemini
 */
export async function processGeminiRequest(contents, model = DEFAULT_MODEL, params = {}) {
  if (!env.geminiApiKey) {
    throw new Error('API key no configurada');
  }
  
  if (!contents) {
    throw new Error('Se requiere un prompt o historial de mensajes');
  }
  
  // Llama al modelo Gemini con timeout y reintentos
  const response = await withTimeoutAndRetry(() => ai.models.generateContent({
    model,
    contents,
    ...params
  }), { timeoutMs: 35000, maxRetries: 2, backoffMs: 2500 });
  
  // Conteo de tokens (si el SDK lo permite)
  if (response.usage && response.usage.totalTokens) {
    incrementTokenCount(response.usage.totalTokens);
  }
  
  return response;
}

/**
 * Procesa una solicitud de function calling a la API de Gemini
 * @param {Object} options - Opciones de la solicitud
 * @returns {Promise<Object>} - Respuesta con function calls
 */
export async function processFunctionCallingRequest({
  prompt,
  model = DEFAULT_MODEL,
  functionDeclarations = [defaultFunctionDeclaration],
  functionCallingMode = 'ANY',
  allowedFunctionNames = ['controlLight']
}) {
  if (!env.geminiApiKey) {
    throw new Error('API key no configurada');
  }
  
  if (!prompt) {
    throw new Error('Se requiere un prompt');
  }
  
  const tools = [{ functionDeclarations }];
  
  const config = {
    toolConfig: {
      functionCallingConfig: {
        mode: functionCallingMode,
        allowedFunctionNames: allowedFunctionNames
      }
    },
    tools
  };
  
  // Llama al modelo Gemini con timeout y reintentos
  const response = await withTimeoutAndRetry(() => ai.models.generateContent({
    model,
    contents: prompt,
    config
  }), { timeoutMs: 35000, maxRetries: 2, backoffMs: 2500 });
  
  return {
    text: response.text,
    functionCalls: response.functionCalls || null
  };
}
